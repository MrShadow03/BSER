{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNQtQRJv1Vcz",
        "outputId": "4e7dff2e-856a-45c3-a938-1e230c6e21f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading ANGRY files:   0%|          | 0/500 [00:08<?, ?it/s]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 82\u001b[0m\n\u001b[0;32m     79\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./saved/dataset_dict12.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m emotion \u001b[38;5;129;01min\u001b[39;00m emotions:\n\u001b[1;32m---> 82\u001b[0m     dataset_dict \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memotion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;66;03m# Load previously saved data\u001b[39;00m\n\u001b[0;32m     85\u001b[0m     existing_data \u001b[38;5;241m=\u001b[39m load_dict_from_csv(output_file)\n",
            "Cell \u001b[1;32mIn[1], line 57\u001b[0m, in \u001b[0;36mclassify_files\u001b[1;34m(path, emotion_label, batch_size)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, files_count, batch_size):\n\u001b[0;32m     56\u001b[0m     batch_files \u001b[38;5;241m=\u001b[39m emotion_file_list[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 57\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m [get_cwt_mel(path, n_fft\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2048\u001b[39m, hop_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m512\u001b[39m, n_mels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m batch_files]\n\u001b[0;32m     58\u001b[0m     emotion_data\u001b[38;5;241m.\u001b[39mextend(batch_data)\n\u001b[0;32m     59\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(batch_files))  \u001b[38;5;66;03m# Update the progress bar\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[1], line 57\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, files_count, batch_size):\n\u001b[0;32m     56\u001b[0m     batch_files \u001b[38;5;241m=\u001b[39m emotion_file_list[i:i \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[1;32m---> 57\u001b[0m     batch_data \u001b[38;5;241m=\u001b[39m [\u001b[43mget_cwt_mel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_fft\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2048\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhop_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_mels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m batch_files]\n\u001b[0;32m     58\u001b[0m     emotion_data\u001b[38;5;241m.\u001b[39mextend(batch_data)\n\u001b[0;32m     59\u001b[0m     pbar\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mlen\u001b[39m(batch_files))  \u001b[38;5;66;03m# Update the progress bar\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[1], line 10\u001b[0m, in \u001b[0;36mget_cwt_mel\u001b[1;34m(path, n_fft, hop_length, n_mels)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cwt_mel\u001b[39m(path, n_fft, hop_length, n_mels):\n\u001b[1;32m---> 10\u001b[0m     y, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     file_length \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msize(y)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file_length \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m128000\u001b[39m:\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\librosa\\core\\audio.py:190\u001b[0m, in \u001b[0;36mload\u001b[1;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# Final cleanup for dtype and contiguity\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mono:\n\u001b[1;32m--> 190\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mto_mono\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    193\u001b[0m     y \u001b[38;5;241m=\u001b[39m resample(y, orig_sr\u001b[38;5;241m=\u001b[39msr_native, target_sr\u001b[38;5;241m=\u001b[39msr, res_type\u001b[38;5;241m=\u001b[39mres_type)\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\librosa\\core\\audio.py:505\u001b[0m, in \u001b[0;36mto_mono\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Convert an audio signal to mono by averaging samples across channels.\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    502\u001b[0m \u001b[38;5;124;03m(117601,)\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    504\u001b[0m \u001b[38;5;66;03m# Validate the buffer.  Stereo is ok here.\u001b[39;00m\n\u001b[1;32m--> 505\u001b[0m \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalid_audio\u001b[49m(y, mono\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    508\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)))\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\lazy_loader\\__init__.py:82\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[0;32m     81\u001b[0m     submod_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 82\u001b[0m     submod \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubmod_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     attr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(submod, name)\n\u001b[0;32m     85\u001b[0m     \u001b[38;5;66;03m# If the attribute lives in a file (module) with the same\u001b[39;00m\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;66;03m# name as the attribute, ensure that the attribute and *not*\u001b[39;00m\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# the module is accessible on the package.\u001b[39;00m\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
            "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\librosa\\util\\utils.py:1218\u001b[0m\n\u001b[0;32m   1203\u001b[0m     lmini[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m xi[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m<\u001b[39m xi[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lmin\n\u001b[0;32m   1209\u001b[0m \u001b[38;5;129;43m@numba\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguvectorize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\n\u001b[0;32m   1211\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoid(float32[:], uint32, uint32, uint32, uint32, float32, uint32, bool_[:])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1212\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoid(float64[:], uint32, uint32, uint32, uint32, float32, uint32, bool_[:])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1213\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoid(int32[:], uint32, uint32, uint32, uint32, float32, uint32, bool_[:])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1214\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvoid(int64[:], uint32, uint32, uint32, uint32, float32, uint32, bool_[:])\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m(n),(),(),(),(),(),()->(n)\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnopython\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43m__peak_pick\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpeaks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1219\u001b[0m \u001b[38;5;250;43m    \u001b[39;49m\u001b[38;5;124;43;03m\"\"\"Vectorized wrapper for the peak-picker\"\"\"\u001b[39;49;00m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Special case the first frame\u001b[39;49;00m\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\np\\ufunc\\decorators.py:206\u001b[0m, in \u001b[0;36mguvectorize.<locals>.wrap\u001b[1;34m(func)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ftylist) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    205\u001b[0m     guvec\u001b[38;5;241m.\u001b[39mdisable_compile()\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mguvec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\np\\ufunc\\gufunc.py:140\u001b[0m, in \u001b[0;36mGUFunc.build_ufunc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_ufunc\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mufunc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgufunc_builder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_ufunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\core\\compiler_lock.py:35\u001b[0m, in \u001b[0;36m_CompilerLock.__call__.<locals>._acquire_compile_lock\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire_compile_lock\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m---> 35\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\np\\ufunc\\ufuncbuilder.py:376\u001b[0m, in \u001b[0;36mGUFuncBuilder.build_ufunc\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sigs:\n\u001b[0;32m    375\u001b[0m     cres \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cres[sig]\n\u001b[1;32m--> 376\u001b[0m     dtypenums, ptr, env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcres\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    377\u001b[0m     type_list\u001b[38;5;241m.\u001b[39mappend(dtypenums)\n\u001b[0;32m    378\u001b[0m     func_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(ptr))\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\np\\ufunc\\ufuncbuilder.py:400\u001b[0m, in \u001b[0;36mGUFuncBuilder.build\u001b[1;34m(self, cres)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[38;5;66;03m# Builder wrapper for ufunc entry point\u001b[39;00m\n\u001b[0;32m    399\u001b[0m signature \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39msignature\n\u001b[1;32m--> 400\u001b[0m info \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_gufunc_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    401\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_parfors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    403\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    405\u001b[0m env \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39menv\n\u001b[0;32m    406\u001b[0m ptr \u001b[38;5;241m=\u001b[39m info\u001b[38;5;241m.\u001b[39mlibrary\u001b[38;5;241m.\u001b[39mget_pointer_to_function(info\u001b[38;5;241m.\u001b[39mname)\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\np\\ufunc\\wrappers.py:502\u001b[0m, in \u001b[0;36mbuild_gufunc_wrapper\u001b[1;34m(py_func, cres, sin, sout, cache, is_parfors)\u001b[0m\n\u001b[0;32m    498\u001b[0m signature \u001b[38;5;241m=\u001b[39m cres\u001b[38;5;241m.\u001b[39msignature\n\u001b[0;32m    499\u001b[0m wrapcls \u001b[38;5;241m=\u001b[39m (_GufuncObjectWrapper\n\u001b[0;32m    500\u001b[0m            \u001b[38;5;28;01mif\u001b[39;00m signature\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;241m==\u001b[39m types\u001b[38;5;241m.\u001b[39mpyobject\n\u001b[0;32m    501\u001b[0m            \u001b[38;5;28;01melse\u001b[39;00m _GufuncWrapper)\n\u001b[1;32m--> 502\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapcls\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpy_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_parfors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_parfors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mbuild()\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\np\\ufunc\\wrappers.py:306\u001b[0m, in \u001b[0;36m_GufuncWrapper.__init__\u001b[1;34m(self, py_func, cres, sin, sout, cache, is_parfors)\u001b[0m\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msout \u001b[38;5;241m=\u001b[39m sout\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_objectmode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mreturn_type \u001b[38;5;241m==\u001b[39m types\u001b[38;5;241m.\u001b[39mpyobject\n\u001b[1;32m--> 306\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;241m=\u001b[39m (\u001b[43mGufWrapperCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpy_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpy_func\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    307\u001b[0m               \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;28;01melse\u001b[39;00m NullCache())\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_parfors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(is_parfors)\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\core\\caching.py:604\u001b[0m, in \u001b[0;36mCache.__init__\u001b[1;34m(self, py_func)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl\u001b[38;5;241m.\u001b[39mlocator\u001b[38;5;241m.\u001b[39mget_cache_path()\n\u001b[0;32m    603\u001b[0m \u001b[38;5;66;03m# This may be a bit strict but avoids us maintaining a magic number\u001b[39;00m\n\u001b[1;32m--> 604\u001b[0m source_stamp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_impl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlocator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_source_stamp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    605\u001b[0m filename_base \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl\u001b[38;5;241m.\u001b[39mfilename_base\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_file \u001b[38;5;241m=\u001b[39m IndexDataCacheFile(cache_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache_path,\n\u001b[0;32m    607\u001b[0m                                       filename_base\u001b[38;5;241m=\u001b[39mfilename_base,\n\u001b[0;32m    608\u001b[0m                                       source_stamp\u001b[38;5;241m=\u001b[39msource_stamp)\n",
            "File \u001b[1;32md:\\Web_Projects\\html\\Officials\\Backend\\AI\\Bangla-Speech-Emotion-Recognition\\.conda\\lib\\site-packages\\numba\\core\\caching.py:165\u001b[0m, in \u001b[0;36m_SourceFileBackedLocatorMixin.get_source_stamp\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m     st \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstat(sys\u001b[38;5;241m.\u001b[39mexecutable)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 165\u001b[0m     st \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_py_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;66;03m# We use both timestamp and size as some filesystems only have second\u001b[39;00m\n\u001b[0;32m    167\u001b[0m \u001b[38;5;66;03m# granularity.\u001b[39;00m\n\u001b[0;32m    168\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m st\u001b[38;5;241m.\u001b[39mst_mtime, st\u001b[38;5;241m.\u001b[39mst_size\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import librosa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pathlib\n",
        "from tqdm import tqdm\n",
        "import csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_cwt_mel(path, n_fft, hop_length, n_mels):\n",
        "    y, sr = librosa.load(path, sr=16000)\n",
        "    file_length = np.size(y)\n",
        "\n",
        "    if file_length < 128000:\n",
        "        y = np.concatenate((y, np.zeros(128000 - file_length)), axis=0)\n",
        "    else:\n",
        "        y = y[:128000]\n",
        "\n",
        "    hop_length = 250\n",
        "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=128)\n",
        "    stft = np.abs(librosa.stft(y, n_fft=254, hop_length=hop_length))\n",
        "    chroma = librosa.feature.chroma_stft(S=stft, n_chroma=128)\n",
        "    log_mel_spectrogram = np.concatenate((mfcc, stft, chroma), axis=1)\n",
        "    log_mel_spectrogram = log_mel_spectrogram.reshape((-1,))\n",
        "\n",
        "    # Clear temporary variables\n",
        "    del mfcc, stft, chroma, y\n",
        "\n",
        "    return log_mel_spectrogram\n",
        "\n",
        "def save_to_csv(filename, data):\n",
        "    df = pd.DataFrame(data)\n",
        "    df.to_csv(filename, mode='a', header=not pathlib.Path(filename).exists(), index=False)\n",
        "\n",
        "def classify_files(path, emotion_label, batch_size=100):\n",
        "    emotion_mapping = {\n",
        "        'ANGRY': 0,\n",
        "        'HAPPY': 1,\n",
        "        'NEUTRAL': 2,\n",
        "        'SAD': 3,\n",
        "        'SURPRISE': 4\n",
        "    }\n",
        "    \n",
        "    wav_path = pathlib.Path(path)\n",
        "    emotion_file_list = [str(file_name) for file_name in wav_path.glob('*.wav') if emotion_label in str(file_name)]\n",
        "\n",
        "    files_count = len(emotion_file_list)\n",
        "    dataset_dict = {\n",
        "        'total': files_count,\n",
        "        'file_dict': {emotion_label: {'represent': emotion_mapping[emotion_label], 'count': files_count, 'all_data': []}}\n",
        "    }\n",
        "\n",
        "    # Initialize the progress bar\n",
        "    emotion_data = []\n",
        "    with tqdm(total=files_count, desc=f\"Loading {emotion_label} files\") as pbar:\n",
        "        for i in range(0, files_count, batch_size):\n",
        "            batch_files = emotion_file_list[i:i + batch_size]\n",
        "            batch_data = [get_cwt_mel(path, n_fft=2048, hop_length=512, n_mels=128) for path in batch_files]\n",
        "            emotion_data.extend(batch_data)\n",
        "            pbar.update(len(batch_files))  # Update the progress bar\n",
        "            \n",
        "    dataset_dict['file_dict'][emotion_label]['all_data'] = emotion_data\n",
        "\n",
        "    return dataset_dict\n",
        "\n",
        "def save_dict_to_csv(dict_data, file_name):\n",
        "    df = pd.DataFrame.from_dict(dict_data, orient='index')\n",
        "    df.to_csv(file_name, mode='a', header=not pathlib.Path(file_name).exists())\n",
        "\n",
        "def load_dict_from_csv(file_name):\n",
        "    if pathlib.Path(file_name).exists():\n",
        "        df = pd.read_csv(file_name, index_col=0)  # Assuming the first column is the index\n",
        "        dict_data = df.to_dict(orient='index')\n",
        "        return dict_data\n",
        "    else:\n",
        "        return {}\n",
        "\n",
        "path = './data/SUBESCO_500'\n",
        "emotions = ['ANGRY', 'HAPPY', 'NEUTRAL', 'SAD', 'SURPRISE']\n",
        "output_file = './saved/dataset_dict12.csv'\n",
        "\n",
        "for emotion in emotions:\n",
        "    dataset_dict = classify_files(path, emotion)\n",
        "    \n",
        "    # Load previously saved data\n",
        "    existing_data = load_dict_from_csv(output_file)\n",
        "    \n",
        "    # Append new data\n",
        "    existing_data.update(dataset_dict['file_dict'])\n",
        "    \n",
        "    # Convert dict to DataFrame and save\n",
        "    df = pd.DataFrame.from_dict(existing_data, orient='index')\n",
        "    df.to_csv(output_file)\n",
        "    \n",
        "    # Clear memory\n",
        "    del dataset_dict, existing_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jGHPyx9l1Vc1"
      },
      "outputs": [],
      "source": [
        "#save the contents of the dictionary to a csv file\n",
        "def save_dict_to_csv(dict, file_name):\n",
        "    with open(file_name, 'w') as f:\n",
        "        writer = csv.writer(f)\n",
        "        for key, value in dict.items():\n",
        "            writer.writerow([key, value])\n",
        "\n",
        "#save_dict_to_csv(dataset_dict, '/content/drive/MyDrive/data/UIU/saved/dataset_dict_UIUxSUST.csv')\n",
        "\n",
        "#load the contents of the dictionary from a csv file\n",
        "def load_dict_from_csv(file_name):\n",
        "    with open(file_name, 'r') as f:\n",
        "        reader = csv.reader(f)\n",
        "        dict = dict(reader)\n",
        "    return dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NN_qUfL1Vc2",
        "outputId": "45205bd1-3573-419c-93c2-974b7b52aa45"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ANGRY\n",
            "500\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 157440000 into shape (128,513,3)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[4], line 127\u001b[0m\n\u001b[0;32m    123\u001b[0m             writer\u001b[38;5;241m.\u001b[39mwriterow([filename])\n\u001b[0;32m    125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m train_data_x, train_data_y, test_data_x, test_data_y\n\u001b[1;32m--> 127\u001b[0m train_data_x, train_data_y, test_data_x, test_data_y \u001b[38;5;241m=\u001b[39m \u001b[43mclassify_files_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data_x:\u001b[39m\u001b[38;5;124m'\u001b[39m, train_data_x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_data_y:\u001b[39m\u001b[38;5;124m'\u001b[39m, train_data_y\u001b[38;5;241m.\u001b[39mshape)\n",
            "Cell \u001b[1;32mIn[4], line 98\u001b[0m, in \u001b[0;36mclassify_files_new\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     95\u001b[0m x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m128\u001b[39m, \u001b[38;5;241m513\u001b[39m\n\u001b[0;32m     96\u001b[0m z \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[1;32m---> 98\u001b[0m train_data_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m test_data_x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(test_data_x, np\u001b[38;5;241m.\u001b[39marray(x_test))\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x, y, z)\n\u001b[0;32m    101\u001b[0m train_data_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(train_data_y, y_train)\n",
            "\u001b[1;31mValueError\u001b[0m: cannot reshape array of size 157440000 into shape (128,513,3)"
          ]
        }
      ],
      "source": [
        "\n",
        "def load_data(path):\n",
        "    train_data_x = []\n",
        "    train_data_y = []\n",
        "    validation_data_x = []\n",
        "    validation_data_y = []\n",
        "    test_data_x = []\n",
        "    test_data_y = []\n",
        "\n",
        "    dataset_dict = load_dict_from_csv('saved/dataset_dict_UIU.csv')\n",
        "\n",
        "    '''Split data set'''\n",
        "    emotion_label_list = dataset_dict['file_dict'].keys()\n",
        "    for emotion_label in emotion_label_list:\n",
        "        x = dataset_dict['file_dict'][emotion_label]['all_data']\n",
        "        count = dataset_dict['file_dict'][emotion_label]['count']\n",
        "        y = np.full(count, dataset_dict['file_dict'][emotion_label]['represent'])\n",
        "\n",
        "        x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.80, random_state=1)\n",
        "\n",
        "        train_data_x = np.append(train_data_x, x_train)\n",
        "        train_data_y = np.append(train_data_y, y_train)\n",
        "\n",
        "        test_data_x = np.append(test_data_x, x_test)\n",
        "        test_data_y = np.append(test_data_y, y_test)\n",
        "    '''\n",
        "    train_data_x=np.array(train_data_x).reshape(len(train_data_y),-1)\n",
        "    with open(path +'/data/train_data_x.csv',\"w+\") as my_csv:\n",
        "      csvWriter = csv.writer(my_csv,delimiter=',')\n",
        "      csvWriter.writerows(train_data_x)\n",
        "\n",
        "    test_data_x=np.array(test_data_x).reshape(len(test_data_y),-1)\n",
        "    with open(path +'/data/test_data_x.csv',\"w+\") as my_csv:\n",
        "      csvWriter = csv.writer(my_csv,delimiter=',')\n",
        "      csvWriter.writerows(test_data_x)\n",
        "    '''\n",
        "\n",
        "\n",
        "    #np.savetxt(path +'/data/train_data_x.csv', np.array(train_data_x))\n",
        "    np.savetxt(path +'/data/train_data_y.csv', train_data_y, delimiter=',')\n",
        "   #np.savetxt(path +'/data/test_data_x.csv', test_data_x, delimiter=',')\n",
        "    np.savetxt(path +'/data/test_data_y.csv', test_data_y, delimiter=',')\n",
        "\n",
        "    x=128 #128\n",
        "    y=128#768 #384 #256\n",
        "    z=5\n",
        "    train_data_x = np.array(train_data_x).reshape(-1, x, y,3)\n",
        "    #train_data_x = np.array(train_data_x).reshape(-1, x, y, z,1)\n",
        "    train_data_y = np.array(train_data_y)\n",
        "    #test_data_x = np.array(test_data_x).reshape(-1, x, y, z,1)\n",
        "    test_data_x = np.array(test_data_x).reshape(-1, x, y,3)\n",
        "    test_data_y = np.array(test_data_y)\n",
        "\n",
        "    return train_data_x,train_data_y,test_data_x,test_data_y\n",
        "\n",
        "def classify_files_new(path):\n",
        "    dataset_dict = {\n",
        "        'total': 0,\n",
        "        'file_dict': {\n",
        "            'ANGRY': {'represent': 0, 'count': 0, 'all_data': []},\n",
        "            'HAPPY': {'represent': 1, 'count': 0, 'all_data': []},\n",
        "            'NEUTRAL': {'represent': 2, 'count': 0, 'all_data': []},\n",
        "            'SAD': {'represent': 3, 'count': 0, 'all_data': []},\n",
        "            'SURPRISE': {'represent': 4, 'count': 0, 'all_data': []}\n",
        "        }\n",
        "    }\n",
        "\n",
        "    wav_path = pathlib.Path(path)\n",
        "    emotion_file_list = [str(file_name) for file_name in wav_path.glob('*.wav')]\n",
        "\n",
        "    train_data_x, train_data_y = [], []\n",
        "    test_data_x, test_data_y = [], []\n",
        "    train_filenames, test_filenames = [], []\n",
        "\n",
        "    emotion_label_list = dataset_dict['file_dict'].keys()\n",
        "    for emotion_label in emotion_label_list:\n",
        "        print(emotion_label)\n",
        "\n",
        "        emotion_classify_file_list = [letter for letter in emotion_file_list if emotion_label in letter]\n",
        "        files_count = len(emotion_classify_file_list)\n",
        "\n",
        "        print(files_count)\n",
        "\n",
        "        dataset_dict['file_dict'][emotion_label]['count'] = files_count\n",
        "        dataset_dict['total'] += files_count\n",
        "\n",
        "        emotion_data = [get_cwt_mel(path, n_fft=2048, hop_length=512, n_mels=128) for path in emotion_classify_file_list]\n",
        "\n",
        "        x = emotion_data\n",
        "        count = dataset_dict['file_dict'][emotion_label]['count']\n",
        "        y = np.full(count, dataset_dict['file_dict'][emotion_label]['represent'])\n",
        "\n",
        "        x_train, x_test, y_train, y_test, train_files, test_files = train_test_split(\n",
        "            x, y, emotion_classify_file_list, train_size=0.80, random_state=1, stratify=y)\n",
        "\n",
        "        x, y = 128, 513\n",
        "        z = 3\n",
        "\n",
        "        train_data_x = np.append(train_data_x, np.array(x_train)).reshape(-1, x, y, z)\n",
        "        test_data_x = np.append(test_data_x, np.array(x_test)).reshape(-1, x, y, z)\n",
        "\n",
        "        train_data_y = np.append(train_data_y, y_train)\n",
        "        test_data_y = np.append(test_data_y, y_test)\n",
        "\n",
        "        train_filenames.extend(train_files)\n",
        "        test_filenames.extend(test_files)\n",
        "\n",
        "    #if the csv folder does not exist, create it\n",
        "    pathlib.Path(path + '/csv').mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    np.savetxt(path + '/csv/train_data_y.csv', train_data_y, delimiter=',')\n",
        "    np.savetxt(path + '/csv/test_data_y.csv', test_data_y, delimiter=',')\n",
        "\n",
        "    with open(path + '/csv/train_filenames.csv', 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['Filename'])\n",
        "        for filename in train_filenames:\n",
        "            writer.writerow([filename])\n",
        "\n",
        "    with open(path + '/csv/test_filenames.csv', 'w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow(['Filename'])\n",
        "        for filename in test_filenames:\n",
        "            writer.writerow([filename])\n",
        "\n",
        "    return train_data_x, train_data_y, test_data_x, test_data_y\n",
        "\n",
        "train_data_x, train_data_y, test_data_x, test_data_y = classify_files_new(path)\n",
        "print('train_data_x:', train_data_x.shape)\n",
        "print('train_data_y:', train_data_y.shape)\n",
        "print('test_data_x:', test_data_x.shape)\n",
        "print('test_data_y:', test_data_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data_x: [[[[-4.90783242e+02 -4.90783242e+02 -4.90783242e+02]\n",
            "   [-4.90783242e+02 -4.90783242e+02 -4.90783242e+02]\n",
            "   [-4.90783242e+02 -4.90783242e+02 -4.90783242e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-4.74816163e+02 -4.70800108e+02 -4.67709909e+02]\n",
            "   [-4.65606069e+02 -4.64455904e+02 -4.63996341e+02]\n",
            "   [-4.63819553e+02 -4.63681920e+02 -4.63337051e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.71804979e+01  3.08497712e+01  3.32292956e+01]\n",
            "   [ 3.45682772e+01  3.51793069e+01  3.54528360e+01]\n",
            "   [ 3.56032362e+01  3.57569459e+01  3.61314387e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.93737385e+01  2.05866954e+01  2.08088860e+01]\n",
            "   [ 2.05756841e+01  2.04487493e+01  2.06065367e+01]\n",
            "   [ 2.09344302e+01  2.14262066e+01  2.19563696e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 5.88736135e-01  4.28201779e-01  5.29485622e-01]\n",
            "   [ 9.11645277e-01  1.22474549e+00  1.22596245e+00]\n",
            "   [ 9.99394642e-01  7.07304917e-01  4.40154320e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 4.17932646e-01  4.02951437e-01  2.88211495e-01]\n",
            "   [ 2.85420814e-01  3.06197267e-01  2.64115337e-01]\n",
            "   [ 1.65213523e-02 -2.30515508e-01 -3.16846410e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.22774032e-02  4.42634589e-01  8.02162622e-01]\n",
            "   [ 7.53442406e-01  4.82179591e-01  2.96888269e-01]\n",
            "   [ 1.12866319e-01 -1.16375853e-01 -1.26730917e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-4.90077229e+02 -4.90077229e+02 -4.90077229e+02]\n",
            "   [-4.90077229e+02 -4.90077229e+02 -4.90077229e+02]\n",
            "   [-4.90077229e+02 -4.90077229e+02 -4.90077229e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-5.22494015e+02 -5.16418688e+02 -5.12935248e+02]\n",
            "   [-5.11829607e+02 -5.12758935e+02 -5.15408585e+02]\n",
            "   [-5.19353834e+02 -5.23809030e+02 -5.28318818e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 7.89849248e+01  8.37893723e+01  8.65065183e+01]\n",
            "   [ 8.73633093e+01  8.66305637e+01  8.46575801e+01]\n",
            "   [ 8.18284065e+01  7.85844935e+01  7.53193015e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.55925201e+01  2.44868788e+01  2.38228529e+01]\n",
            "   [ 2.36721622e+01  2.40484865e+01  2.50054443e+01]\n",
            "   [ 2.65103973e+01  2.81969556e+01  3.00270087e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.19714262e+00  1.10069675e+00  9.89247006e-01]\n",
            "   [ 9.10310230e-01  8.13291365e-01  7.18519489e-01]\n",
            "   [ 6.98219400e-01  6.59291215e-01  7.24128211e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.27163731e+00  1.51289245e+00  1.60245013e+00]\n",
            "   [ 1.59942082e+00  1.48922017e+00  1.35440324e+00]\n",
            "   [ 1.23367010e+00  1.19558913e+00  1.30604873e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 6.94819041e-01  1.27605549e+00  1.65958390e+00]\n",
            "   [ 1.84391492e+00  1.90234756e+00  1.81637641e+00]\n",
            "   [ 1.56122169e+00  1.49730581e+00  1.63301218e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-5.14857389e+02 -5.12513040e+02 -5.11393131e+02]\n",
            "   [-5.11312506e+02 -5.12128656e+02 -5.13355923e+02]\n",
            "   [-5.14239351e+02 -5.14603488e+02 -5.14541475e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.98387131e+01  4.25996216e+01  4.38235997e+01]\n",
            "   [ 4.37577590e+01  4.26034342e+01  4.09697829e+01]\n",
            "   [ 3.97851026e+01  3.92931610e+01  3.93664151e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.30949126e+01  3.45720911e+01  3.49857680e+01]\n",
            "   [ 3.45404446e+01  3.34336124e+01  3.20806015e+01]\n",
            "   [ 3.10595988e+01  3.06170557e+01  3.06448971e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.34292075e+00  1.35149257e+00  1.23794317e+00]\n",
            "   [ 1.23847165e+00  1.20336881e+00  1.04251153e+00]\n",
            "   [ 9.31980371e-01  8.30068951e-01  7.52420309e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.64590546e+00  1.81169317e+00  1.76424108e+00]\n",
            "   [ 1.77496699e+00  1.73859825e+00  1.57579047e+00]\n",
            "   [ 1.48266193e+00  1.37754330e+00  1.26935358e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.17501434e+00  1.34080871e+00  1.34245801e+00]\n",
            "   [ 1.36091575e+00  1.34649989e+00  1.25116901e+00]\n",
            "   [ 1.19905351e+00  1.12936658e+00  1.04853575e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-5.19488926e+02 -5.17680999e+02 -5.17127570e+02]\n",
            "   [-5.17653233e+02 -5.18901953e+02 -5.20339273e+02]\n",
            "   [-5.21326592e+02 -5.21564114e+02 -5.20830816e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 4.13132782e+01  4.34063357e+01  4.39426557e+01]\n",
            "   [ 4.31514325e+01  4.14522207e+01  3.95012193e+01]\n",
            "   [ 3.81433219e+01  3.77889499e+01  3.86882887e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.35677864e+01  3.45917410e+01  3.45896595e+01]\n",
            "   [ 3.37217124e+01  3.22087396e+01  3.04860908e+01]\n",
            "   [ 2.92392371e+01  2.88430245e+01  2.93893711e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 3.76185020e-01  2.97789005e-01  2.39814928e-01]\n",
            "   [ 2.03203345e-01  2.07068944e-01  2.00066856e-01]\n",
            "   [ 2.50124121e-01  1.35169573e-01 -2.15750400e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 5.43909627e-01  5.00954259e-01  5.04472836e-01]\n",
            "   [ 5.21349325e-01  5.69539744e-01  6.10653885e-01]\n",
            "   [ 6.80008681e-01  5.80930473e-01  2.57244625e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 4.33788908e-01  4.26390711e-01  4.62992931e-01]\n",
            "   [ 4.98905765e-01  5.46047858e-01  5.93718629e-01]\n",
            "   [ 6.47849704e-01  5.93389132e-01  4.03338324e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]]\n",
            "train_data_y: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2.\n",
            " 2. 2. 2. 2. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.\n",
            " 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n",
            "test_data_x: [[[[-6.30035677e+02 -6.28756989e+02 -6.28293947e+02]\n",
            "   [-6.28419230e+02 -6.28838792e+02 -6.29144965e+02]\n",
            "   [-6.29028643e+02 -6.28536463e+02 -6.28041786e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.76173861e+01  2.92671840e+01  2.98126537e+01]\n",
            "   [ 2.95334013e+01  2.88848951e+01  2.84256717e+01]\n",
            "   [ 2.85693017e+01  2.92258083e+01  2.98853097e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 2.41778142e+01  2.54050217e+01  2.56726383e+01]\n",
            "   [ 2.51667808e+01  2.44017278e+01  2.38873711e+01]\n",
            "   [ 2.39757595e+01  2.45251019e+01  2.50801627e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[-1.04480287e+00 -1.18391482e+00 -1.15620070e+00]\n",
            "   [-9.16151478e-01 -6.01997122e-01 -2.59988997e-01]\n",
            "   [-8.50276745e-02  3.66461622e-02  3.58724998e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[-9.79620851e-01 -1.12451010e+00 -1.08922444e+00]\n",
            "   [-8.04205329e-01 -5.06695547e-01 -2.31093852e-01]\n",
            "   [-1.03615471e-01 -3.90487205e-02 -6.66017627e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[-5.86963780e-01 -6.76935114e-01 -6.50530383e-01]\n",
            "   [-4.51104944e-01 -2.63645104e-01 -1.05712374e-01]\n",
            "   [-3.74909915e-02 -1.41719704e-02 -4.06784624e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-4.73468297e+02 -4.72040794e+02 -4.71589662e+02]\n",
            "   [-4.72184164e+02 -4.73675254e+02 -4.75258926e+02]\n",
            "   [-4.76414008e+02 -4.76741584e+02 -4.76678810e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.61703500e+01  3.79896866e+01  3.84522514e+01]\n",
            "   [ 3.75530965e+01  3.55005248e+01  3.33107841e+01]\n",
            "   [ 3.17087036e+01  3.12572331e+01  3.13486803e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.12365583e+01  3.25362321e+01  3.25928684e+01]\n",
            "   [ 3.15969556e+01  2.97342449e+01  2.76960459e+01]\n",
            "   [ 2.61894478e+01  2.57726272e+01  2.58715079e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 7.06875712e-02  8.97516775e-02  7.59269381e-02]\n",
            "   [ 1.29928574e-01  2.80103749e-01  3.10514984e-01]\n",
            "   [ 3.68018863e-01  3.35194350e-01  2.90035954e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[-1.28538642e-01 -1.14958183e-01 -7.65485050e-02]\n",
            "   [ 1.30792012e-02  1.40179223e-01  1.37423955e-01]\n",
            "   [ 1.12118534e-01  3.06174229e-02 -4.45348937e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[-1.31203740e-01 -1.19474212e-01 -6.78605039e-02]\n",
            "   [ 9.26308482e-03  8.72396555e-02  7.72515889e-02]\n",
            "   [ 3.41519336e-02 -3.71909199e-02 -9.82263328e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-4.91363729e+02 -4.91363729e+02 -4.91363729e+02]\n",
            "   [-4.91363729e+02 -4.91363729e+02 -4.91363729e+02]\n",
            "   [-4.91363729e+02 -4.91363729e+02 -4.91363729e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " ...\n",
            "\n",
            "\n",
            " [[[-4.54346098e+02 -4.47935922e+02 -4.44019396e+02]\n",
            "   [-4.42401697e+02 -4.42909801e+02 -4.44830067e+02]\n",
            "   [-4.47330004e+02 -4.49516023e+02 -4.51096919e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 5.19345568e+01  5.71382026e+01  6.03565822e+01]\n",
            "   [ 6.17804176e+01  6.16955562e+01  6.05453774e+01]\n",
            "   [ 5.89032130e+01  5.73721222e+01  5.63723112e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.10863226e+01  3.04734424e+01  2.99301095e+01]\n",
            "   [ 2.95120288e+01  2.95341928e+01  2.99433825e+01]\n",
            "   [ 3.07398544e+01  3.15901393e+01  3.25868867e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.53807669e+00  1.91075175e+00  1.90029290e+00]\n",
            "   [ 1.67696511e+00  1.28946873e+00  9.35059226e-01]\n",
            "   [ 6.04463687e-01  5.00024170e-01  3.52450552e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.76362565e+00  1.72514129e+00  1.74121617e+00]\n",
            "   [ 1.60071861e+00  1.40509298e+00  1.26216952e+00]\n",
            "   [ 1.18886003e+00  1.09256686e+00  9.57436772e-01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.45136140e+00  1.12300337e+00  1.07686507e+00]\n",
            "   [ 1.09215287e+00  1.31618959e+00  1.52858381e+00]\n",
            "   [ 1.62349075e+00  1.37960346e+00  1.23123968e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-5.15864709e+02 -5.12233283e+02 -5.10095814e+02]\n",
            "   [-5.09341908e+02 -5.09644723e+02 -5.10491771e+02]\n",
            "   [-5.11366922e+02 -5.11919927e+02 -5.12053228e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 4.57839919e+01  4.92793749e+01  5.11400561e+01]\n",
            "   [ 5.15479263e+01  5.08620486e+01  4.97111404e+01]\n",
            "   [ 4.87086920e+01  4.82728456e+01  4.83945379e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 3.43280065e+01  3.50219037e+01  3.49109093e+01]\n",
            "   [ 3.42345432e+01  3.31933172e+01  3.21659875e+01]\n",
            "   [ 3.14996510e+01  3.15127281e+01  3.20494122e+01]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 1.22230256e+00  1.35907632e+00  1.32933935e+00]\n",
            "   [ 1.15429833e+00  9.05665099e-01  6.30423307e-01]\n",
            "   [ 6.60760937e-01  8.90277330e-01  1.04033941e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 1.71105341e-01  3.36320215e-01  4.55194036e-01]\n",
            "   [ 5.18965359e-01  5.19436744e-01  5.22471705e-01]\n",
            "   [ 7.90163696e-01  1.24734752e+00  1.65639638e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[-7.16821415e-01 -6.55433285e-01 -5.19622191e-01]\n",
            "   [-3.45840247e-01 -2.04803700e-01 -3.02010672e-02]\n",
            "   [ 2.80946592e-01  6.69190859e-01  1.04419600e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]\n",
            "\n",
            "\n",
            " [[[-5.15125266e+02 -5.15125266e+02 -5.15125266e+02]\n",
            "   [-5.15125266e+02 -5.15125266e+02 -5.15125266e+02]\n",
            "   [-5.15125266e+02 -5.15125266e+02 -5.13017710e+02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  2.93971006e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  2.81889687e+00]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  ...\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00 -4.62550759e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00 -2.98420816e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            "  [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00 -1.46001927e-02]\n",
            "   ...\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "   [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]]]\n",
            "test_data_y: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 2. 3. 3. 3. 3. 3.\n",
            " 3. 3. 3. 3. 3. 3. 3. 3. 3. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4. 4.]\n"
          ]
        }
      ],
      "source": [
        "print('train_data_x:', train_data_x)\n",
        "print('train_data_y:', train_data_y)\n",
        "print('test_data_x:', test_data_x)\n",
        "print('test_data_y:', test_data_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwT-Z87m1Vc3",
        "outputId": "553944f2-9d7a-4eb4-f636-e5967b5d1443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train_data_x shape: (400, 128, 1025, 3)\n",
            "train_data_y shape: (400,)\n",
            "test_data_x shape: (100, 128, 1025, 3)\n",
            "test_data_y shape: (100,)\n"
          ]
        }
      ],
      "source": [
        "def save_array_to_npy(array, file_name):\n",
        "    np.save(file_name, array)\n",
        "\n",
        "def load_array_from_npy(file_name):\n",
        "    return np.load(file_name)\n",
        "\n",
        "# Example usage\n",
        "save_array_to_npy(train_data_x, path + '/saved/train_data_x.npy')\n",
        "save_array_to_npy(train_data_y, path + '/saved/train_data_y.npy')\n",
        "save_array_to_npy(test_data_x, path + '/saved/test_data_x.npy')\n",
        "save_array_to_npy(test_data_y, path + '/saved/test_data_y.npy')\n",
        "\n",
        "# Loading the arrays\n",
        "train_data_x = load_array_from_npy(path + '/saved/train_data_x.npy')\n",
        "train_data_y = load_array_from_npy(path + '/saved/train_data_y.npy')\n",
        "test_data_x = load_array_from_npy(path + '/saved/test_data_x.npy')\n",
        "test_data_y = load_array_from_npy(path + '/saved/test_data_y.npy')\n",
        "\n",
        "print('train_data_x shape:', train_data_x.shape)\n",
        "print('train_data_y shape:', train_data_y.shape)\n",
        "print('test_data_x shape:', test_data_x.shape)\n",
        "print('test_data_y shape:', test_data_y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_OcUkob1Vc4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gnhg42pK1Vc4",
        "outputId": "21b66870-740e-4fef-ef97-1bca61d38fa1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train data X shape: (400, 128, 1025, 3)\n",
            "Train data Y shape: (400, 5)\n",
            "Test data X shape: (100, 128, 1025, 3)\n",
            "Test data Y shape: (100, 5)\n"
          ]
        }
      ],
      "source": [
        "from numpy.core.fromnumeric import shape\n",
        "import librosa\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import os\n",
        "# import pywt\n",
        "import csv\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import normalize, to_categorical\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras,nn\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def model3d(input_shape, num_classes):\n",
        "\n",
        "    model = keras.Sequential(name='model3d')\n",
        "\n",
        "    #LFLB1\n",
        "    model.add(layers.Conv3D(filters=64,kernel_size=3,strides=1,padding='same',input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling3D(pool_size=(2,2,1), strides=(2,2,1)))\n",
        "\n",
        "    #LFLB2\n",
        "    model.add(layers.Conv3D(filters=64,kernel_size=3,strides=1, padding='same', ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling3D(pool_size=(4,4,1), strides=(4,4,1)))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "    #LFLB3\n",
        "    model.add(layers.Conv3D(filters=128,kernel_size=3,strides=1,padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling3D(pool_size=(4,4,1), strides=(4,4,1)))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "\n",
        "    #LFLB4\n",
        "    model.add(layers.Conv3D(filters=128,kernel_size=3,strides=1,padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling3D(pool_size=(4,4,1), strides=(4,4,1)))\n",
        "\n",
        "    #model.add(layers.Reshape((-1, 128)))\n",
        "    model.add(layers.TimeDistributed(layers.Flatten()))\n",
        "\n",
        "    #LSTM\n",
        "    #model.add(layers.LSTM(256))\n",
        "    model.add(layers.Bidirectional(layers.LSTM(256)))\n",
        "\n",
        "    #model.add(keras.layers.Dense(128,activation=nn.relu))\n",
        "    #model.add(layers.Dense(128,activation=nn.relu))\n",
        "    model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0006, decay=1e-6)\n",
        "\n",
        "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def model2dv2(input_shape, num_classes):\n",
        "\n",
        "    model = keras.Sequential(name='model2d')\n",
        "\n",
        "    #LFLB1\n",
        "    model.add(layers.Conv2D(filters=64,kernel_size=(3,3),strides=1,padding='same',input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "    #LFLB2\n",
        "    model.add(layers.Conv2D(filters=64,kernel_size=(3,3),strides=1, padding='same', ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "    #LFLB3\n",
        "    model.add(layers.Conv2D(filters=128,kernel_size=(3,3),strides=1,padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "\n",
        "\n",
        "    #LFLB4\n",
        "    model.add(layers.Conv2D(filters=128,kernel_size=(3,3),strides=1,padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=(4,4), strides=(4,4)))\n",
        "\n",
        "    #model.add(layers.Reshape((-1, 128)))\n",
        "    model.add(layers.TimeDistributed(layers.Flatten()))\n",
        "\n",
        "    #LSTM\n",
        "    #model.add(layers.LSTM(256))\n",
        "    model.add(layers.Bidirectional(layers.LSTM(256)))\n",
        "\n",
        "    #model.add(keras.layers.Dense(128,activation=nn.relu))\n",
        "    #model.add(layers.Dense(128,activation=nn.relu))\n",
        "    model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0006, decay=1e-6)\n",
        "\n",
        "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def model2d(input_shape, num_classes):\n",
        "\n",
        "    model = keras.Sequential(name='model2d')\n",
        "\n",
        "    #LFLB1\n",
        "    model.add(layers.Conv2D(filters=64,kernel_size=3,strides=1,padding='same',input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "    #LFLB2\n",
        "    model.add(layers.Conv2D(filters=64,kernel_size=3,strides=1, padding='same', ))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=4, strides=4))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "    #LFLB3\n",
        "    model.add(layers.Conv2D(filters=128,kernel_size=3,strides=1,padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=4, strides=4))\n",
        "    #model.add(layers.MaxPooling2D(pool_size=2, strides=2))\n",
        "\n",
        "\n",
        "\n",
        "    #LFLB4\n",
        "    model.add(layers.Conv2D(filters=128,kernel_size=3,strides=1,padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('relu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=4, strides=4))\n",
        "\n",
        "    #model.add(layers.Reshape((-1, 128)))\n",
        "    model.add(layers.TimeDistributed(layers.Flatten()))\n",
        "\n",
        "    #LSTM\n",
        "    #model.add(layers.LSTM(256))\n",
        "    model.add(layers.Bidirectional(layers.LSTM(256)))\n",
        "\n",
        "    #model.add(keras.layers.Dense(128,activation=nn.relu))\n",
        "    #model.add(layers.Dense(128,activation=nn.relu))\n",
        "    model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    #opt = keras.optimizers.Adam(learning_rate=0.0006, decay=1e-6)\n",
        "    opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0006, decay=1e-6)\n",
        "\n",
        "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "def model2CNN2F(input_shape, num_classes):\n",
        "\n",
        "    model = keras.Sequential(name='model2d')\n",
        "\n",
        "    #LFLB1\n",
        "    model.add(layers.Conv2D(filters=128,kernel_size=3,strides=1,padding='same',input_shape=input_shape))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('elu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=4, strides=4))\n",
        "\n",
        "    #LFLB3\n",
        "    model.add(layers.Conv2D(filters=64,kernel_size=3,strides=1,padding='same'))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.Activation('elu'))\n",
        "    model.add(layers.MaxPooling2D(pool_size=8, strides=8))\n",
        "\n",
        "    #model.add(layers.Reshape((-1, 128)))\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(128,activation=nn.relu))\n",
        "    model.add(layers.Dense(units=num_classes, activation='softmax'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    opt = keras.optimizers.Adam(learning_rate=0.0006, decay=1e-6)\n",
        "\n",
        "    model.compile(optimizer=opt,loss='categorical_crossentropy',metrics=['categorical_accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "# physical_device = tf.config.experimental.list_physical_devices(\"GPU\")\n",
        "# tf.config.experimental.set_memory_growth(physical_device[0], True)\n",
        "print(\"Train data X shape:\", train_data_x.shape)\n",
        "print(\"Train data Y shape:\", train_data_y.shape)\n",
        "print(\"Test data X shape:\", test_data_x.shape)\n",
        "print(\"Test data Y shape:\", test_data_y.shape)\n",
        "\n",
        "def train(train_data_x, train_data_y, emotion, emotionNumber, epochs=10):\n",
        "    #256,513,1025\n",
        "    model = model2d(input_shape=(128,1025, 3), num_classes=emotionNumber)\n",
        "\n",
        "    model.summary()\n",
        "    es = EarlyStopping(monitor='val_categorical_accuracy',mode='max',verbose=1,patience=20)\n",
        "\n",
        "    mc = ModelCheckpoint(path+'/model/'+emotion+'_max_model.keras',monitor='val_categorical_accuracy',mode='max',verbose=1,save_best_only=True)\n",
        "    history=model.fit(train_data_x, train_data_y,validation_data=(test_data_x, test_data_y),epochs=epochs,batch_size=10,verbose=2,callbacks=[es,mc])\n",
        "    acc=history.history['categorical_accuracy'][len(history.history['categorical_accuracy']) - 1]\n",
        "    model.save(path+'/model/'+emotion+'_max_model.keras')\n",
        "\n",
        "    return acc\n",
        "\n",
        "def test(test_data_x, test_data_y,emotion):\n",
        "\n",
        "    new_model = load_model(path+'/model/'+emotion+'_max_model.keras')\n",
        "    history=new_model.evaluate(test_data_x, test_data_y, batch_size=1)\n",
        "    predict=new_model.predict(test_data_x)\n",
        "    return history[1]\n",
        "\n",
        "def maxIndex(data):\n",
        "  max=data[0]\n",
        "  index=0\n",
        "  for i in range(1,len(data)):\n",
        "    if(max<data[i]):\n",
        "      max=data[i]\n",
        "      index=i\n",
        "  return index\n",
        "\n",
        "def test_emotion(test_data_x, test_data_y, total, emotion, path):\n",
        "    model_path = os.path.join(path, 'model', emotion + '_max_model.keras')\n",
        "\n",
        "    # Check if the file exists before loading\n",
        "    if not os.path.isfile(model_path):\n",
        "        raise ValueError(f\"File not found: {model_path}. Please ensure the file is an accessible `.keras` zip file.\")\n",
        "\n",
        "    new_model = load_model(model_path)\n",
        "\n",
        "    # Ensure the labels are one-hot encoded for testing\n",
        "    test_data_y = to_categorical(test_data_y, num_classes=total)\n",
        "\n",
        "    # Evaluate the model\n",
        "    history = new_model.evaluate(test_data_x, test_data_y, batch_size=10)\n",
        "    print(f\"Test accuracy: {history[1]}\")\n",
        "\n",
        "    # Predict and generate confusion matrix\n",
        "    predictions = new_model.predict(test_data_x, batch_size=10)\n",
        "    confusion_matrix = np.zeros((total, total))\n",
        "\n",
        "    for i in range(len(test_data_y)):\n",
        "        actual_label = np.argmax(test_data_y[i])\n",
        "        predicted_label = np.argmax(predictions[i])\n",
        "        confusion_matrix[actual_label][predicted_label] += 1\n",
        "\n",
        "    # Ensure the directory exists\n",
        "    save_dir = os.path.join(path, 'data')\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Save the confusion matrix to CSV\n",
        "    confusion_csv_path = os.path.join(save_dir, emotion + '_confusion.csv')\n",
        "    with open(confusion_csv_path, \"w\", newline='') as my_csv:\n",
        "        csvWriter = csv.writer(my_csv, delimiter=',')\n",
        "        csvWriter.writerows(confusion_matrix)\n",
        "\n",
        "    print(f\"Confusion matrix saved to: {confusion_csv_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-NvfkD3_1Vc5",
        "outputId": "becb2571-d193-4212-9145-f9090c688410"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 128, 1025, 64)     1792      \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 128, 1025, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 128, 1025, 64)     0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 64, 512, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 64, 512, 64)       36928     \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 64, 512, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 64, 512, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 16, 128, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 128, 128)      73856     \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 16, 128, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 16, 128, 128)      0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 4, 32, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 4, 32, 128)        147584    \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 4, 32, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 4, 32, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 1, 8, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDi  (None, 1, 1024)           0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 512)               2623488   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2887749 (11.02 MB)\n",
            "Trainable params: 2886981 (11.01 MB)\n",
            "Non-trainable params: 768 (3.00 KB)\n",
            "_________________________________________________________________\n",
            "Model: \"model2d\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_12 (Conv2D)          (None, 128, 1025, 64)     1792      \n",
            "                                                                 \n",
            " batch_normalization_12 (Ba  (None, 128, 1025, 64)     256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_12 (Activation)  (None, 128, 1025, 64)     0         \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 64, 512, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_13 (Conv2D)          (None, 64, 512, 64)       36928     \n",
            "                                                                 \n",
            " batch_normalization_13 (Ba  (None, 64, 512, 64)       256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_13 (Activation)  (None, 64, 512, 64)       0         \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 16, 128, 64)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_14 (Conv2D)          (None, 16, 128, 128)      73856     \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 16, 128, 128)      512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_14 (Activation)  (None, 16, 128, 128)      0         \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 4, 32, 128)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2d_15 (Conv2D)          (None, 4, 32, 128)        147584    \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 4, 32, 128)        512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_15 (Activation)  (None, 4, 32, 128)        0         \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 1, 8, 128)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " time_distributed_3 (TimeDi  (None, 1, 1024)           0         \n",
            " stributed)                                                      \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 512)               2623488   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 2565      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2887749 (11.02 MB)\n",
            "Trainable params: 2886981 (11.01 MB)\n",
            "Non-trainable params: 768 (3.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/30\n",
            "\n",
            "Epoch 1: val_categorical_accuracy improved from -inf to 0.37000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 237s - loss: 1.6009 - categorical_accuracy: 0.2850 - val_loss: 1.4179 - val_categorical_accuracy: 0.3700 - 237s/epoch - 6s/step\n",
            "Epoch 2/30\n",
            "\n",
            "Epoch 2: val_categorical_accuracy improved from 0.37000 to 0.43000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 222s - loss: 1.1750 - categorical_accuracy: 0.5300 - val_loss: 1.2122 - val_categorical_accuracy: 0.4300 - 222s/epoch - 6s/step\n",
            "Epoch 3/30\n",
            "\n",
            "Epoch 3: val_categorical_accuracy improved from 0.43000 to 0.68000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 231s - loss: 0.9015 - categorical_accuracy: 0.6600 - val_loss: 0.9167 - val_categorical_accuracy: 0.6800 - 231s/epoch - 6s/step\n",
            "Epoch 4/30\n",
            "\n",
            "Epoch 4: val_categorical_accuracy improved from 0.68000 to 0.69000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 222s - loss: 0.6666 - categorical_accuracy: 0.7775 - val_loss: 0.7957 - val_categorical_accuracy: 0.6900 - 222s/epoch - 6s/step\n",
            "Epoch 5/30\n",
            "\n",
            "Epoch 5: val_categorical_accuracy improved from 0.69000 to 0.79000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 229s - loss: 0.4835 - categorical_accuracy: 0.8375 - val_loss: 0.5961 - val_categorical_accuracy: 0.7900 - 229s/epoch - 6s/step\n",
            "Epoch 6/30\n",
            "\n",
            "Epoch 6: val_categorical_accuracy did not improve from 0.79000\n",
            "40/40 - 228s - loss: 0.3598 - categorical_accuracy: 0.9000 - val_loss: 0.5892 - val_categorical_accuracy: 0.7500 - 228s/epoch - 6s/step\n",
            "Epoch 7/30\n",
            "\n",
            "Epoch 7: val_categorical_accuracy improved from 0.79000 to 0.85000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 230s - loss: 0.2801 - categorical_accuracy: 0.9225 - val_loss: 0.4578 - val_categorical_accuracy: 0.8500 - 230s/epoch - 6s/step\n",
            "Epoch 8/30\n",
            "\n",
            "Epoch 8: val_categorical_accuracy did not improve from 0.85000\n",
            "40/40 - 229s - loss: 0.1776 - categorical_accuracy: 0.9350 - val_loss: 0.4992 - val_categorical_accuracy: 0.7900 - 229s/epoch - 6s/step\n",
            "Epoch 9/30\n",
            "\n",
            "Epoch 9: val_categorical_accuracy did not improve from 0.85000\n",
            "40/40 - 228s - loss: 0.1231 - categorical_accuracy: 0.9750 - val_loss: 0.4420 - val_categorical_accuracy: 0.8400 - 228s/epoch - 6s/step\n",
            "Epoch 10/30\n",
            "\n",
            "Epoch 10: val_categorical_accuracy did not improve from 0.85000\n",
            "40/40 - 229s - loss: 0.1002 - categorical_accuracy: 0.9775 - val_loss: 0.3644 - val_categorical_accuracy: 0.8300 - 229s/epoch - 6s/step\n",
            "Epoch 11/30\n",
            "\n",
            "Epoch 11: val_categorical_accuracy did not improve from 0.85000\n",
            "40/40 - 228s - loss: 0.1334 - categorical_accuracy: 0.9700 - val_loss: 0.4244 - val_categorical_accuracy: 0.8000 - 228s/epoch - 6s/step\n",
            "Epoch 12/30\n",
            "\n",
            "Epoch 12: val_categorical_accuracy improved from 0.85000 to 0.87000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 221s - loss: 0.0946 - categorical_accuracy: 0.9775 - val_loss: 0.3697 - val_categorical_accuracy: 0.8700 - 221s/epoch - 6s/step\n",
            "Epoch 13/30\n",
            "\n",
            "Epoch 13: val_categorical_accuracy improved from 0.87000 to 0.88000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 227s - loss: 0.0340 - categorical_accuracy: 0.9975 - val_loss: 0.3085 - val_categorical_accuracy: 0.8800 - 227s/epoch - 6s/step\n",
            "Epoch 14/30\n",
            "\n",
            "Epoch 14: val_categorical_accuracy improved from 0.88000 to 0.89000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 223s - loss: 0.0122 - categorical_accuracy: 1.0000 - val_loss: 0.2931 - val_categorical_accuracy: 0.8900 - 223s/epoch - 6s/step\n",
            "Epoch 15/30\n",
            "\n",
            "Epoch 15: val_categorical_accuracy improved from 0.89000 to 0.91000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 226s - loss: 0.0076 - categorical_accuracy: 1.0000 - val_loss: 0.2832 - val_categorical_accuracy: 0.9100 - 226s/epoch - 6s/step\n",
            "Epoch 16/30\n",
            "\n",
            "Epoch 16: val_categorical_accuracy did not improve from 0.91000\n",
            "40/40 - 228s - loss: 0.0039 - categorical_accuracy: 1.0000 - val_loss: 0.2612 - val_categorical_accuracy: 0.9000 - 228s/epoch - 6s/step\n",
            "Epoch 17/30\n",
            "\n",
            "Epoch 17: val_categorical_accuracy did not improve from 0.91000\n",
            "40/40 - 226s - loss: 0.0034 - categorical_accuracy: 1.0000 - val_loss: 0.2550 - val_categorical_accuracy: 0.9000 - 226s/epoch - 6s/step\n",
            "Epoch 18/30\n",
            "\n",
            "Epoch 18: val_categorical_accuracy did not improve from 0.91000\n",
            "40/40 - 228s - loss: 0.0026 - categorical_accuracy: 1.0000 - val_loss: 0.2612 - val_categorical_accuracy: 0.9000 - 228s/epoch - 6s/step\n",
            "Epoch 19/30\n",
            "\n",
            "Epoch 19: val_categorical_accuracy did not improve from 0.91000\n",
            "40/40 - 227s - loss: 0.0022 - categorical_accuracy: 1.0000 - val_loss: 0.2542 - val_categorical_accuracy: 0.9000 - 227s/epoch - 6s/step\n",
            "Epoch 20/30\n",
            "\n",
            "Epoch 20: val_categorical_accuracy did not improve from 0.91000\n",
            "40/40 - 222s - loss: 0.0020 - categorical_accuracy: 1.0000 - val_loss: 0.2660 - val_categorical_accuracy: 0.9100 - 222s/epoch - 6s/step\n",
            "Epoch 21/30\n",
            "\n",
            "Epoch 21: val_categorical_accuracy improved from 0.91000 to 0.92000, saving model to /content/drive/MyDrive/data/UIU/speech_subset_SUST/model/BSER-UIUxSUST_max_model.keras\n",
            "40/40 - 225s - loss: 0.0017 - categorical_accuracy: 1.0000 - val_loss: 0.2637 - val_categorical_accuracy: 0.9200 - 225s/epoch - 6s/step\n",
            "Epoch 22/30\n",
            "\n",
            "Epoch 22: val_categorical_accuracy did not improve from 0.92000\n",
            "40/40 - 231s - loss: 0.0014 - categorical_accuracy: 1.0000 - val_loss: 0.2653 - val_categorical_accuracy: 0.9100 - 231s/epoch - 6s/step\n",
            "Epoch 23/30\n",
            "\n",
            "Epoch 23: val_categorical_accuracy did not improve from 0.92000\n",
            "40/40 - 231s - loss: 0.0013 - categorical_accuracy: 1.0000 - val_loss: 0.2737 - val_categorical_accuracy: 0.9100 - 231s/epoch - 6s/step\n",
            "Epoch 24/30\n",
            "\n",
            "Epoch 24: val_categorical_accuracy did not improve from 0.92000\n",
            "40/40 - 231s - loss: 0.0011 - categorical_accuracy: 1.0000 - val_loss: 0.2844 - val_categorical_accuracy: 0.9100 - 231s/epoch - 6s/step\n",
            "Epoch 25/30\n",
            "\n",
            "Epoch 25: val_categorical_accuracy did not improve from 0.92000\n",
            "40/40 - 230s - loss: 9.5834e-04 - categorical_accuracy: 1.0000 - val_loss: 0.2857 - val_categorical_accuracy: 0.9100 - 230s/epoch - 6s/step\n",
            "Epoch 26/30\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-5a07a5980c58>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'BSER-UIUxSUST'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memotion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-50-5f5a2a07cd37>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data_x, train_data_y, emotion, emotionNumber, epochs)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0mmc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/model/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_max_model.keras'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_categorical_accuracy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m     \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'categorical_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/model/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0memotion\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_max_model.keras'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_data_x = load_array_from_npy(path+'/saved/train_data_x.npy')\n",
        "train_data_y = load_array_from_npy(path+'/saved/train_data_y.npy')\n",
        "test_data_x = load_array_from_npy(path+'/saved/test_data_x.npy')\n",
        "test_data_y = load_array_from_npy(path+'/saved/test_data_y.npy')\n",
        "\n",
        "train_data_y = to_categorical(train_data_y)\n",
        "test_data_y = to_categorical(test_data_y)\n",
        "emotion='BSER-UIUxSUST'\n",
        "\n",
        "acc=train(train_data_x, train_data_y, emotion, 5, 30)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKSEA5Cl1Vc5",
        "outputId": "b4dea1de-c25c-429d-a01e-ae36fb4d826f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10/10 [==============================] - 19s 1s/step - loss: 0.2637 - categorical_accuracy: 0.9200\n",
            "Test accuracy: 0.9200000166893005\n",
            "10/10 [==============================] - 15s 1s/step\n",
            "Confusion matrix saved to: /content/drive/MyDrive/data/UIU/speech_subset_SUST/data/BSER-UIUxSUST_confusion.csv\n"
          ]
        }
      ],
      "source": [
        "test_data_x = load_array_from_npy(path+'/saved/test_data_x.npy')\n",
        "test_data_y = load_array_from_npy(path+'/saved/test_data_y.npy')\n",
        "\n",
        "emotion = 'BSER-UIUxSUST'\n",
        "#path = './data/UIUxSUST'\n",
        "\n",
        "test_emotion(test_data_x, test_data_y, 5, emotion, path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "z8xHoEJ-1Vc6",
        "outputId": "4d931f9c-738d-4b3b-a92c-a3c2cdc4675f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def plot_confusion_matrix(csv_path):\n",
        "    # Load the confusion matrix from CSV\n",
        "    confusion_matrix = pd.read_csv(csv_path, header=None).values\n",
        "\n",
        "    # Define the labels for the confusion matrix\n",
        "    labels = ['ANGRY', 'DISGUST', 'HAPPY', 'NEUTRAL', 'SAD']\n",
        "\n",
        "    # Create a heatmap\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(confusion_matrix, annot=True, fmt='g', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "\n",
        "    # Add labels, title and axes\n",
        "    plt.xlabel('Predicted labels')\n",
        "    plt.ylabel('True labels')\n",
        "    plt.title('BSER-UIUxSUST Confusion Matrix')\n",
        "    plt.show()\n",
        "\n",
        "# Example usage\n",
        "csv_path = path+'/data/BSER-UIUxSUST_confusion.csv'\n",
        "plot_confusion_matrix(csv_path)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
