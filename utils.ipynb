{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "def copy_emotion_files(source_folder, target_folder, emotions, num_files=100):\n",
    "    # Create target folder if it doesn't exist\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.makedirs(target_folder)\n",
    "    \n",
    "    # Dictionary to keep track of the number of copied files for each emotion\n",
    "    emotion_counts = defaultdict(int)\n",
    "    \n",
    "    # Get all files in the source folder\n",
    "    files = Path(source_folder).glob('*')\n",
    "    \n",
    "    for file in files:\n",
    "        for emotion in emotions:\n",
    "            if emotion in file.name and emotion_counts[emotion] < num_files:\n",
    "                # Copy file to the target folder\n",
    "                shutil.copy(str(file), target_folder)\n",
    "                emotion_counts[emotion] += 1\n",
    "                print(f'Copied: {file.name} to {target_folder}')\n",
    "                \n",
    "                # Stop copying if the required number of files for each emotion is reached\n",
    "                if all(count >= num_files for count in emotion_counts.values()):\n",
    "                    return\n",
    "\n",
    "# Example usage\n",
    "source_folder = './data/SUST'  # Replace with your source folder path\n",
    "target_folder = './data/speech_subset'  # Replace with your target folder path\n",
    "emotions = ['ANGRY', 'HAPPY', 'NEUTRAL', 'SAD', 'SURPRISE']  # Replace with your emotions\n",
    "\n",
    "copy_emotion_files(source_folder, target_folder, emotions, num_files=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moved 194 files for emotion 'NEUTRAL' to ./data/SUBESCOxUIU/train\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def transfer_random_files(src_dir, dst_dir, num_files_per_emotion, move=False):\n",
    "    emotions = ['ANGRY', 'HAPPY', 'SAD', 'SURPRISE']\n",
    "\n",
    "    # Create the destination directory if it does not exist\n",
    "    Path(dst_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for emotion in emotions:\n",
    "        # Find all files for the current emotion\n",
    "        emotion_files = list(Path(src_dir).glob(f'*{emotion}*.wav'))\n",
    "\n",
    "        if len(emotion_files) < num_files_per_emotion:\n",
    "            print(f\"Warning: Not enough files for {emotion}. Found only {len(emotion_files)} files.\")\n",
    "            num_files_to_copy = len(emotion_files)\n",
    "        else:\n",
    "            num_files_to_copy = num_files_per_emotion\n",
    "\n",
    "        # Randomly select the specified number of files\n",
    "        selected_files = random.sample(emotion_files, num_files_to_copy)\n",
    "\n",
    "        # Copy the selected files to the destination directory\n",
    "        for file_path in selected_files:\n",
    "            if move:\n",
    "                shutil.move(file_path, dst_dir)\n",
    "            else:\n",
    "                shutil.copy(file_path, dst_dir)\n",
    "    action = \"moved\" if move else \"copied\"\n",
    "    print(f\"{action.capitalize()} {num_files_per_emotion} files for each emotion to {dst_dir}\")\n",
    "\n",
    "def copy_or_move_emotion_files(emotion, num_files, src_dir, dst_dir, move=False):\n",
    "    # Create the destination directory if it does not exist\n",
    "    Path(dst_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Find all files for the specified emotion\n",
    "    emotion_files = list(Path(src_dir).glob(f'*{emotion}*.wav'))\n",
    "\n",
    "    if len(emotion_files) < num_files:\n",
    "        print(f\"Warning: Not enough files for {emotion}. Found only {len(emotion_files)} files.\")\n",
    "        num_files_to_process = len(emotion_files)\n",
    "    else:\n",
    "        num_files_to_process = num_files\n",
    "\n",
    "    # Randomly select the specified number of files\n",
    "    selected_files = random.sample(emotion_files, num_files_to_process)\n",
    "\n",
    "    # Copy or move the selected files to the destination directory\n",
    "    for file_path in selected_files:\n",
    "        if move:\n",
    "            shutil.move(file_path, dst_dir)\n",
    "        else:\n",
    "            shutil.copy(file_path, dst_dir)\n",
    "\n",
    "    action = \"moved\" if move else \"copied\"\n",
    "    print(f\"{action.capitalize()} {num_files_to_process} files for emotion '{emotion}' to {dst_dir}\")\n",
    "\n",
    "# Example usage\n",
    "src_directory = './data/UIU'\n",
    "num_files = 194\n",
    "dst_directory = './data/SUBESCOxUIU/train'\n",
    "emotion = 'NEUTRAL'\n",
    "\n",
    "copy_or_move_emotion_files(emotion, num_files, src_directory, dst_directory, True)\n",
    "# transfer_random_files(src_directory, dst_directory, num_files, move=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import csv\n",
    "\n",
    "def split_dataset(directory, train_csv, test_csv, train_ratio=0.8):\n",
    "    # Dictionary to store files by emotion\n",
    "    emotion_files = {}\n",
    "\n",
    "    # Traverse through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".wav\"):\n",
    "            # Extract emotion from filename\n",
    "            emotions = [\"ANGRY\", \"HAPPY\", \"NEUTRAL\", \"SAD\", \"SURPRISE\"]\n",
    "            for emotion in emotions:\n",
    "                if emotion in filename.upper():\n",
    "                    if emotion not in emotion_files:\n",
    "                        emotion_files[emotion] = []\n",
    "                    emotion_files[emotion].append(filename)\n",
    "                    break\n",
    "\n",
    "    # Lists to hold training and testing filenames\n",
    "    train_files = []\n",
    "    test_files = []\n",
    "\n",
    "    # Split each emotion's files into training and testing\n",
    "    for emotion, files in emotion_files.items():\n",
    "        random.shuffle(files)\n",
    "        split_point = int(len(files) * train_ratio)\n",
    "        train_files.extend(files[:split_point])\n",
    "        test_files.extend(files[split_point:])\n",
    "\n",
    "    # Write training files to CSV\n",
    "    with open(train_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for file in train_files:\n",
    "            writer.writerow([file])\n",
    "\n",
    "    # Write testing files to CSV\n",
    "    with open(test_csv, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        for file in test_files:\n",
    "            writer.writerow([file])\n",
    "\n",
    "# Example usage\n",
    "data_dir = './data/uiu-labelData'\n",
    "emotions = ['ANGRY', 'HAPPY', 'NEUTRAL', 'SAD', 'SURPRISE']\n",
    "train_csv = './data/uiu-labelData/split/train_files.csv'\n",
    "test_csv = './data/uiu-labelData/split/test_files.csv'\n",
    "split_dataset(data_dir, train_csv, test_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "\n",
    "def retrieve_files_from_csv(directory, train_csv, test_csv):\n",
    "    def read_csv(csv_file):\n",
    "        with open(csv_file, 'r') as file:\n",
    "            reader = csv.reader(file)\n",
    "            return [row[0] for row in reader]\n",
    "\n",
    "    train_files = read_csv(train_csv)\n",
    "    test_files = read_csv(test_csv)\n",
    "\n",
    "    train_paths = [os.path.join(directory, filename) for filename in train_files]\n",
    "    test_paths = [os.path.join(directory, filename) for filename in test_files]\n",
    "\n",
    "    return train_paths, test_paths\n",
    "\n",
    "# Example usage\n",
    "directory = './data/uiu-labelData/split'\n",
    "train_csv = './data/uiu-labelData/split/train_files.csv'\n",
    "test_csv = './data/uiu-labelData/split/test_files.csv'\n",
    "train_paths, test_paths = retrieve_files_from_csv(directory, train_csv, test_csv)\n",
    "\n",
    "print(\"Training files:\")\n",
    "for path in train_paths:\n",
    "    print(path)\n",
    "\n",
    "print(\"\\nTesting files:\")\n",
    "for path in test_paths:\n",
    "    print(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def copy_files_except_list(csv_file, source_dir, target_dir):\n",
    "    # Read the filenames from the CSV file\n",
    "    with open(csv_file, 'r') as f:\n",
    "        filenames_to_exclude = {os.path.basename(line.strip()) for line in f.readlines()[1:]}  # Skip the header line and extract only the filename\n",
    "    # Ensure the target directory exists\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "\n",
    "    # Copy only .wav files from source_dir to target_dir except those in filenames_to_exclude\n",
    "    for filename in os.listdir(source_dir):\n",
    "        print(filename)\n",
    "        full_path = os.path.join(source_dir, filename)\n",
    "        if os.path.isfile(full_path) and filename.endswith('.wav') and filename not in filenames_to_exclude:\n",
    "            target_path = os.path.join(target_dir, filename)\n",
    "            shutil.copy2(full_path, target_path)\n",
    "\n",
    "# Usage\n",
    "csv_file = './data/SUBESCOxUIU/csv/train_filenames.csv'\n",
    "source_dir = './data/SUBESCO_900'\n",
    "target_dir = 'data/test-data/SUBESCO_900'\n",
    "copy_files_except_list(csv_file, source_dir, target_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def add_suffix_to_wav_files(directory, suffix):\n",
    "    # Loop through all files in the directory\n",
    "    for filename in os.listdir(directory):\n",
    "        # Construct full file path\n",
    "        full_path = os.path.join(directory, filename)\n",
    "        # Check if it is a .wav file and not a directory\n",
    "        if os.path.isfile(full_path) and filename.endswith('.wav'):\n",
    "            # Split the filename and extension\n",
    "            name, ext = os.path.splitext(filename)\n",
    "            # Create the new filename with the suffix\n",
    "            new_filename = f\"{name}_{suffix}{ext}\"\n",
    "            # Construct full new file path\n",
    "            new_full_path = os.path.join(directory, new_filename)\n",
    "            # Rename the file\n",
    "            os.rename(full_path, new_full_path)\n",
    "\n",
    "# Usage\n",
    "directory = 'path_to_your_directory'\n",
    "suffix = 'your_suffix'\n",
    "add_suffix_to_wav_files(directory, suffix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def count_files_by_emotion(csv_file, emotions):\n",
    "    with open(csv_file, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        filenames = [row[0] for row in reader]\n",
    "    \n",
    "    emotion_counts = {emotion: 0 for emotion in emotions}\n",
    "    \n",
    "    for filename in filenames:\n",
    "        for emotion in emotions:\n",
    "            if emotion in filename:\n",
    "                emotion_counts[emotion] += 1\n",
    "                break\n",
    "    \n",
    "    return emotion_counts\n",
    "\n",
    "def draw_emotion_counts_table(train_csv, test_csv):\n",
    "    emotions = ['ANGRY', 'HAPPY', 'NEUTRAL', 'SAD', 'SURPRISE']\n",
    "    train_counts = count_files_by_emotion(train_csv, emotions)\n",
    "    test_counts = count_files_by_emotion(test_csv, emotions)\n",
    "\n",
    "    data = {\n",
    "        'Emotion': emotions,\n",
    "        'Train Count': [train_counts[emotion] for emotion in emotions],\n",
    "        'Test Count': [test_counts[emotion] for emotion in emotions]\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    print(df)\n",
    "\n",
    "    # Plotting table\n",
    "    fig, ax = plt.subplots(figsize=(8, len(df) * 0.5))\n",
    "    ax.axis('tight')\n",
    "    ax.axis('off')\n",
    "    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(12)\n",
    "    table.scale(1, 1.5)\n",
    "    plt.title(\"SUST-Count of Train and Test Files for Each Emotion\")\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "train_csv = './data/SUBESCO/split/train_files.csv'\n",
    "test_csv = './data/SUBESCO/split/test_files.csv'\n",
    "draw_emotion_counts_table(train_csv, test_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANGRY\n",
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 261/261 [00:23<00:00, 11.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HAPPY\n",
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 261/261 [00:09<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEUTRAL\n",
      "248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 248/248 [00:08<00:00, 28.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAD\n",
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 261/261 [00:09<00:00, 28.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SURPRISE\n",
      "261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 261/261 [00:09<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1292, 128, 257, 3)\n",
      "(1292,)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "\n",
    "def save_array_to_npy(array, file_name):\n",
    "    np.save(file_name, array)\n",
    "\n",
    "def load_array_from_npy(file_name):\n",
    "    return np.load(file_name)\n",
    "\n",
    "def get_cwt_mel(path, n_fft, hop_length, n_mels):\n",
    "    \n",
    "    y, sr = librosa.load(path, sr=16000)\n",
    "    file_length = np.size(y)\n",
    "    \n",
    "    duration = 4\n",
    "    samples = duration * sr\n",
    "\n",
    "    if file_length < samples:\n",
    "        y = np.concatenate((y, np.zeros(samples - file_length)), axis=0)\n",
    "    else:\n",
    "        y = y[:samples]\n",
    "\n",
    "    hop_length = 250 #125=1025, 250=513, 501=256,1001\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=128)\n",
    "    stft = np.abs(librosa.stft(y, n_fft=254, hop_length=hop_length))\n",
    "    chroma = librosa.feature.chroma_stft(S=stft, n_chroma=128)\n",
    "    log_mel_spectrogram = np.concatenate((mfcc, stft, chroma), axis=1)\n",
    "    log_mel_spectrogram = log_mel_spectrogram.reshape((-1,))\n",
    "    # print(f\"log_mel_spectrogram shape = {log_mel_spectrogram.shape}\")\n",
    "\n",
    "    # Clear temporary variables\n",
    "    del mfcc, stft, chroma, y\n",
    "\n",
    "    return log_mel_spectrogram\n",
    "\n",
    "def classify_files_new(path):\n",
    "    dataset_dict = {\n",
    "        'total': 0,\n",
    "        'file_dict': {\n",
    "            'ANGRY': {'represent': 0, 'count': 0, 'all_data': []},\n",
    "            'HAPPY': {'represent': 1, 'count': 0, 'all_data': []},\n",
    "            'NEUTRAL': {'represent': 2, 'count': 0, 'all_data': []},\n",
    "            'SAD': {'represent': 3, 'count': 0, 'all_data': []},\n",
    "            'SURPRISE': {'represent': 4, 'count': 0, 'all_data': []}\n",
    "        }\n",
    "    }\n",
    "\n",
    "    wav_path = pathlib.Path(path)\n",
    "    emotion_file_list = [str(file_name) for file_name in wav_path.glob('*.wav')]\n",
    "\n",
    "    train_data_x, train_data_y = [], []\n",
    "    test_data_x, test_data_y = [], []\n",
    "    train_filenames, test_filenames = [], []\n",
    "\n",
    "    emotion_label_list = dataset_dict['file_dict'].keys()\n",
    "    for emotion_label in emotion_label_list:\n",
    "        print(emotion_label)\n",
    "\n",
    "        emotion_classify_file_list = [letter for letter in emotion_file_list if emotion_label in letter]\n",
    "        files_count = len(emotion_classify_file_list)\n",
    "        \n",
    "        print(files_count)\n",
    "\n",
    "        dataset_dict['file_dict'][emotion_label]['count'] = files_count\n",
    "        dataset_dict['total'] += files_count\n",
    "\n",
    "        emotion_data = [get_cwt_mel(path, n_fft=2048, hop_length=512, n_mels=128) for path in tqdm(emotion_classify_file_list, desc=\"Processing files\")]\n",
    "\n",
    "        x = emotion_data\n",
    "        count = dataset_dict['file_dict'][emotion_label]['count']\n",
    "        y = np.full(count, dataset_dict['file_dict'][emotion_label]['represent'])\n",
    "        \n",
    "        # x_train, x_test, y_train, y_test, train_files, test_files = train_test_split(\n",
    "        #     x, y, emotion_classify_file_list, train_size=.999999, random_state=1, stratify=y)\n",
    "        \n",
    "        # 100% training data\n",
    "        x_train, x_test, y_train, y_test, train_files, test_files = x, [], y, [], emotion_classify_file_list, []\n",
    "\n",
    "        # x, y, z = 128, 513, 3\n",
    "        x, y, z = 128, 257, 3\n",
    "        \n",
    "        # #create the npy folder if it does not exist\n",
    "        # pathlib.Path(path + '/npy').mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # # save the partial train data\n",
    "        # save_array_to_npy(x_train, path + '/npy/' + emotion_label + '_x_train.npy')\n",
    "        # save_array_to_npy(y_train, path + '/npy/' + emotion_label + '_y_train.npy')\n",
    "\n",
    "        train_data_x = np.append(train_data_x, np.array(x_train)).reshape(-1, x, y, z)\n",
    "        test_data_x = np.append(test_data_x, np.array(x_test)).reshape(-1, x, y, z)\n",
    "\n",
    "        train_data_y = np.append(train_data_y, y_train)\n",
    "        test_data_y = np.append(test_data_y, y_test)\n",
    "\n",
    "    #     train_filenames.extend(train_files)\n",
    "    #     test_filenames.extend(test_files)\n",
    "\n",
    "    # #if the csv folder does not exist, create it\n",
    "    # pathlib.Path(path + '/csv').mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # np.savetxt(path + '/csv/train_data_y.csv', train_data_y, delimiter=',')\n",
    "    # np.savetxt(path + '/csv/test_data_y.csv', test_data_y, delimiter=',')\n",
    "\n",
    "    return train_data_x, train_data_y, test_data_x, test_data_y\n",
    "\n",
    "path = './data/SUBESCOxUIU/test'\n",
    "train_data_x, train_data_y, test_data_x, test_data_y = classify_files_new(path)\n",
    "\n",
    "print(train_data_x.shape)\n",
    "print(train_data_y.shape)\n",
    "# print(test_data_x.shape)\n",
    "# print(test_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_data_x shape: (1292, 128, 257, 3)\n",
      "test_data_y shape: (1292,)\n"
     ]
    }
   ],
   "source": [
    "def save_array_to_npy(array, file_name):\n",
    "    np.save(file_name, array)\n",
    "\n",
    "def load_array_from_npy(file_name):\n",
    "    return np.load(file_name)\n",
    "\n",
    "data_type = 'test'\n",
    "\n",
    "#if saved directory does not exist, create it\n",
    "pathlib.Path(path + '/npy').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "save_array_to_npy(train_data_x, path + f\"/npy/{data_type}_data_x.npy\")\n",
    "save_array_to_npy(train_data_y, path + f\"/npy/{data_type}_data_y.npy\")\n",
    "\n",
    "del train_data_x, train_data_y, test_data_x, test_data_y\n",
    "\n",
    "train_data_x = load_array_from_npy(path + f\"/npy/{data_type}_data_x.npy\")\n",
    "train_data_y = load_array_from_npy(path + f\"/npy/{data_type}_data_y.npy\")\n",
    "\n",
    "print(f\"{data_type}_data_x shape:\", train_data_x.shape)\n",
    "print(f\"{data_type}_data_y shape:\", train_data_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing files: 100%|██████████| 6466/6466 [01:30<00:00, 71.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total .wav files: 6466\n",
      "Average audio duration: 3.876932452973861 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "from tqdm import tqdm\n",
    "\n",
    "def calculate_avg_audio_duration(directory):\n",
    "    total_duration = 0.0\n",
    "    wav_files_count = 0\n",
    "\n",
    "    # Get the list of all .wav files in the directory\n",
    "    wav_files = [f for f in os.listdir(directory) if f.endswith('.wav') and os.path.isfile(os.path.join(directory, f))]\n",
    "    \n",
    "    for filename in tqdm(wav_files, desc=\"Processing files\"):\n",
    "        filepath = os.path.join(directory, filename)\n",
    "        with wave.open(filepath, 'r') as wav_file:\n",
    "            frames = wav_file.getnframes()\n",
    "            rate = wav_file.getframerate()\n",
    "            duration = frames / float(rate)\n",
    "            total_duration += duration\n",
    "            wav_files_count += 1\n",
    "\n",
    "    if wav_files_count == 0:\n",
    "        return 0.0, 0  # No .wav files found\n",
    "\n",
    "    avg_duration = total_duration / wav_files_count\n",
    "    return avg_duration, wav_files_count\n",
    "\n",
    "# Usage\n",
    "directory = './data/SUBESCOxUIU'\n",
    "avg_duration, total_files = calculate_avg_audio_duration(directory)\n",
    "print(f\"Total .wav files: {total_files}\")\n",
    "print(f\"Average audio duration: {avg_duration} seconds\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
